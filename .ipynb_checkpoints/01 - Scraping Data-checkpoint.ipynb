{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import html2text as ht\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Billboard for song titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"https://www.billboard.com/charts/year-end/2017/hot-100-songs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    bad = {\"\\\\\\\\n+\": \"\\n\", \n",
    "           \"\\n+\": \"\\n\", \n",
    "           \"\\n\": \" - \",\n",
    "           \"\\[.{0,}?\\]\": \"\", \n",
    "           \"\\(.{0,}?\\)\": \"\"}\n",
    "    \n",
    "    for x in bad:\n",
    "        text = re.sub(x, bad[x], text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def find_songs(text):\n",
    "    \n",
    "    s = \"[0-9]{1,3} - !.+? !\"\n",
    "    songs = [x.group() for x in list(re.finditer(s, text))]\n",
    "    return songs\n",
    "\n",
    "def get_titles(songs):\n",
    "    repl = {\"- ! -\": \":::\", \"- \\*.+\": \"\", \"- !\": \"\"}\n",
    "    for i in range(len(songs)):\n",
    "        for j in repl:\n",
    "            songs[i] = re.sub(j, repl[j], songs[i])\n",
    "        songs[i] = songs[i].strip()\n",
    "        \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = \"SELECT A YEAR\"\n",
    "page = requests.get(path)\n",
    "filler = [\" and \", \"featuring\", \" & \", \" x \", \" / \"]\n",
    "\n",
    "data = ht.html2text(str(page.content))\n",
    "data = clean_text(data)\n",
    "data = data[re.search(sub, data).end():]\n",
    "\n",
    "songs = find_songs(data)\n",
    "songs = np.array([[y.strip() for y in re.split(\"\\:\\:\\:| - \", x)] for x in get_titles(songs)])\n",
    "# take out filler words, such as and, &, featuring\n",
    "for i in range(len(songs[:, 2])):\n",
    "    for j in filler:\n",
    "        if re.search(j, songs[i, 2], flags = re.I) != None:\n",
    "            songs[i, 2] = \", \".join(x.strip() for x in re.split(j, songs[i, 2], flags = re.I))\n",
    "df = pd.DataFrame({\"Rank\": songs[:, 0], \"Name\": songs[:, 1], \"Artists\": songs[:, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_lyric_link(artists, name, both = False):\n",
    "    \n",
    "\n",
    "    headers = {\"Authorization\": \"Bearer \" + client_token}\n",
    "    link = \"https://api.genius.com/search?q=\"\n",
    "    space = \"%20\"\n",
    "    name_repl = {\"Beyonce\": \"Beyoncé\", \n",
    "                 \"Amine\": \"Aminé\",\n",
    "                 \"D.R.A.M.\": \"DRAM\",\n",
    "                 \"$ign\": \"\\$ign\"}\n",
    "\n",
    "    artists = re.sub(\",\", \"\", artists)\n",
    "    name = re.sub(\",\", \"\", name)\n",
    "    if both:\n",
    "        page = requests.get(link + re.sub(\" \", space, name) +\n",
    "                            space + re.sub(\" \", space, artists), headers = headers)\n",
    "    else:\n",
    "        page = requests.get(link + re.sub(\" \", space, name), headers = headers)\n",
    "    page = json.loads(page.content)[\"response\"][\"hits\"] #data\n",
    "    check = [re.sub(\",\", \"\", x) for x in artists.split(\" \") + name.split(\" \") if x not in string.punctuation]\n",
    "    for i in name_repl:\n",
    "        if i in check:\n",
    "            check.remove(i)\n",
    "            check.append(name_repl[i])\n",
    "    top = []\n",
    "    #print(page, check)\n",
    "    \n",
    "    #print(link + re.sub(\" \", space, name) +\n",
    "    #                    space + re.sub(\" \", space, artists), check, page)\n",
    "    \n",
    "    \n",
    "    if len(page) == 1:\n",
    "        return page[0][\"result\"][\"path\"]\n",
    "    else:\n",
    "        for i in range(len(page)):\n",
    "            c = 0\n",
    "            for j in check:\n",
    "                if re.search(j, page[i][\"result\"][\"full_title\"], flags = re.I | re.S) != None:\n",
    "                    c += 1\n",
    "                    #print(c)\n",
    "                    #print(page[i][\"result\"][\"full_title\"])\n",
    "            #print(c, len(check))\n",
    "            if c == len(check):\n",
    "                return page[i][\"result\"][\"path\"]\n",
    "            #for j in \n",
    "            #try:\n",
    "            #    top.append(page[i][\"result\"][\"stats\"][\"pageviews\"])\n",
    "            #except KeyError:\n",
    "            #    top.append(-1)\n",
    "        \n",
    "    if both == False:\n",
    "        return get_lyric_link(artists, name, True)\n",
    "    \n",
    "    top = []\n",
    "    #if here, find most popular song\n",
    "    for j in range(len(page)):\n",
    "        try:\n",
    "            top.append(page[i][\"result\"][\"stats\"][\"pageviews\"])\n",
    "        except KeyError:\n",
    "            top.append(-1)\n",
    "    print(top)\n",
    "    return page[np.argmax(top)][\"result\"][\"path\"]\n",
    "\n",
    "    #\n",
    "        \n",
    "    #return None#page[np.argmax(top)][\"result\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lyrics(row, snip):\n",
    "    \n",
    "    base_link = \"https://genius.com\"\n",
    "    \n",
    "    genre_sub = {\"\\\"\": \" \", \"genius\": \"\"}\n",
    "    lyric_regex = row[\"Name\"] + \".{0,20}?Lyrics.+?More on Genius\"\n",
    "    genre_regex = \"genres\\\":\\[.+?\\]\"\n",
    "    track_info_regex = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?remixed by\"\n",
    "    track_info_regex2 = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?cover by\"\n",
    "    date_regex = \"release date.{0,15}?20[0-9][0-9]\"\n",
    "    write_regex = \"Written By\\n+.+?\\n\"\n",
    "    data = BeautifulSoup(requests.get(base_link + snip).content, \"lxml\").get_text()\n",
    "\n",
    "    #subset data\n",
    "    data = data[re.search(base_link + snip, data).end():]\n",
    "    #print(data)\n",
    "    lyrics = re.search(lyric_regex, data, flags = re.I | re.S).group()[:-15]\n",
    "    genre = re.search(\"\\[.+?\\]\", re.search(genre_regex, data, flags = re.I | re.S).group()).group()[1:-1]\n",
    "    for k in genre_sub:\n",
    "        genre = re.sub(k, genre_sub[k], genre, flags = re.I)\n",
    "    #try:\n",
    "    #    track_info = re.search(track_info_regex, data, flags = re.I | re.S).group()\n",
    "    #except AttributeError:\n",
    "    #    track_info = re.search(track_info_regex2, data, flags = re.I | re.S).group()\n",
    "    date = re.split(\"\\n+\", re.search(date_regex, data, flags = re.I | re.S).group())[-1]\n",
    "    write = [x for x in re.split(\"\\n+\", re.search(write_regex, data, flags = re.I | re.S).group()) if x != \"\"][-1]\n",
    "\n",
    "    return date, genre, write, lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#i = 84\n",
    "#temp = get_lyric_link(df.iloc[i][\"Artists\"],  df.iloc[i][\"Name\"])\n",
    "#d, g, w, l = scrape_lyrics(df.iloc[i], temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "genre = []\n",
    "write = []\n",
    "lyrics = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    temp = get_lyric_link(df.iloc[i][\"Artists\"],  df.iloc[i][\"Name\"])\n",
    "    d, g, w, l = scrape_lyrics(df.iloc[i], temp)\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "    dates.append(d)\n",
    "    genre.append(g)\n",
    "    write.append(w)\n",
    "    lyrics.append(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = dates\n",
    "df[\"Genre\"] = genre\n",
    "df[\"Writing Credits\"] = write\n",
    "df[\"Lyrics\"] = lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Billboard_2017.csv\", header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Genius for lyrics, genre, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Song\n",
    "\n",
    "Artist/Group\n",
    "\n",
    "Billboard rank [or peak rank?]\n",
    "\n",
    "Year\n",
    "\n",
    "Genre [if available]\n",
    "\n",
    "Writing Credits\n",
    "\n",
    "Lyrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
