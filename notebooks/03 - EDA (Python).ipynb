{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from gensim.models import word2vec\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library = \"C:\\\\Users\\\\liblabs-user\\\\Desktop\\\\song-authorship\\\\data\"\n",
    "laptop = \"not yet\"\n",
    "desktop = \"C:\\\\Users\\\\Sam\\\\Desktop\\\\song authorship\\\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for f in csv.reader(open(desktop + \"\\\\Billboard_2017.csv\", \"r\", encoding = \"utf-8\", errors = \"backslashreplace\")):\n",
    "    arr.append(f)\n",
    "arr = np.array(arr)\n",
    "\n",
    "df = pd.DataFrame({arr[0, i]: arr[1:,i] for i in range(len(arr[0,:]))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the entire dataset as the training set. We use the same regex for splitting sentences as we did in the R notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = \"([^A-Za-z\\\\d#@']+|'[^A-Za-z\\\\d#@]+)\"\n",
    "sents = []\n",
    "bad = [\" \", \"' '\", \"',\"]\n",
    "\n",
    "for x in range(len(df)):\n",
    "    tmp = df.Lyrics[x].split(\"\\n\")\n",
    "    for y in range(len(tmp)):\n",
    "        sents.append([x.strip().lower() for x in re.split(reg, tmp[y]) \n",
    "                      if ((x.strip() not in bad) and (x.strip() not in string.punctuation))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 50\n",
    "min_word_count = 5\n",
    "num_workers = 4     # Number of parallel threads\n",
    "context = 10       # Context window size\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = word2vec.Word2Vec(sents,\n",
    "                          workers=num_workers,\n",
    "                          size=num_features,\n",
    "                          min_count=min_word_count,\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar words to negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('another', 0.9989797472953796),\n",
       " ('5', 0.998936116695404),\n",
       " ('him', 0.99889075756073),\n",
       " ('over', 0.998849093914032),\n",
       " ('change', 0.9988404512405396),\n",
       " (\"she's\", 0.9988253116607666),\n",
       " ('rock', 0.9988189935684204),\n",
       " ('same', 0.9988166093826294),\n",
       " ('everything', 0.9988166093826294),\n",
       " ('our', 0.9988161325454712)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"kill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('two', 0.9984617829322815),\n",
       " ('had', 0.9984425902366638),\n",
       " ('people', 0.9984099864959717),\n",
       " ('niggas', 0.9983963966369629),\n",
       " ('all', 0.9983333945274353),\n",
       " ('these', 0.9983216524124146),\n",
       " ('rockstar', 0.9983116984367371),\n",
       " ('have', 0.9983013868331909),\n",
       " ('thing', 0.9982846975326538),\n",
       " ('in', 0.9982770681381226)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('over', 0.9995201826095581),\n",
       " ('l', 0.9994511604309082),\n",
       " ('same', 0.9994324445724487),\n",
       " ('another', 0.9993886351585388),\n",
       " ('was', 0.9993852972984314),\n",
       " ('from', 0.9993643164634705),\n",
       " ('everything', 0.9993547797203064),\n",
       " ('though', 0.9993487596511841),\n",
       " ('man', 0.9993354678153992),\n",
       " ('fake', 0.9993325471878052)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"lie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all', 0.999268114566803),\n",
       " (\"i'll\", 0.999219536781311),\n",
       " ('can', 0.9992034435272217),\n",
       " (\"'cause\", 0.999191164970398),\n",
       " ('every', 0.999167263507843),\n",
       " ('wait', 0.9991501569747925),\n",
       " ('niggas', 0.999147891998291),\n",
       " ('was', 0.999127984046936),\n",
       " ('good', 0.9991205930709839),\n",
       " ('whole', 0.9991117119789124)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"hurt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lil', 0.9991902112960815),\n",
       " ('break', 0.9964742660522461),\n",
       " ('gun', 0.994915246963501),\n",
       " ('hold', 0.9937004446983337),\n",
       " ('ready', 0.9936116933822632),\n",
       " ('go', 0.9933769106864929),\n",
       " ('humble', 0.9923690557479858),\n",
       " ('let', 0.9916518330574036),\n",
       " ('bag', 0.991624653339386),\n",
       " ('together', 0.9900668859481812)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bitch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar words to neutral / positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lit', 0.9933951497077942),\n",
       " ('god', 0.9928451776504517),\n",
       " ('everyday', 0.9927563667297363),\n",
       " ('huh', 0.9917480945587158),\n",
       " ('yuh', 0.9911311864852905),\n",
       " ('savage', 0.990744948387146),\n",
       " ('bank', 0.9904979467391968),\n",
       " ('gente', 0.9904606342315674),\n",
       " ('account', 0.9904073476791382),\n",
       " ('mercy', 0.9902795553207397)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"yeah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stop', 0.9993760585784912),\n",
       " ('more', 0.9992494583129883),\n",
       " (\"can't\", 0.9992430210113525),\n",
       " (\"'cause\", 0.9991942644119263),\n",
       " ('new', 0.9991869926452637),\n",
       " ('at', 0.9991333484649658),\n",
       " ('baby', 0.9991272687911987),\n",
       " ('this', 0.9991180896759033),\n",
       " ('he', 0.9991148710250854),\n",
       " ('real', 0.9991146326065063)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"feeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fall', 0.999199628829956),\n",
       " ('4', 0.9991658926010132),\n",
       " ('every', 0.9991360902786255),\n",
       " ('these', 0.9991295337677002),\n",
       " ('change', 0.9990853071212769),\n",
       " ('rock', 0.9990829825401306),\n",
       " (\"i'll\", 0.9990694522857666),\n",
       " ('away', 0.9990686178207397),\n",
       " ('old', 0.9990661144256592),\n",
       " ('through', 0.9990653395652771)]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"kiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'em\", 0.9990774393081665),\n",
       " ('ever', 0.9990666508674622),\n",
       " ('our', 0.9989465475082397),\n",
       " ('cash', 0.9989407062530518),\n",
       " ('seen', 0.9989093542098999),\n",
       " ('another', 0.9989083409309387),\n",
       " ('why', 0.9988938570022583),\n",
       " ('high', 0.9988917112350464),\n",
       " (\"i'll\", 0.9988910555839539),\n",
       " ('2', 0.9988408088684082)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"promise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random words (really, chants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('simple', 0.9977555274963379),\n",
       " ('atlanta', 0.9975080490112305),\n",
       " ('east', 0.9974144697189331),\n",
       " ('heart', 0.9968806505203247),\n",
       " ('uh', 0.9966961741447449),\n",
       " ('woo', 0.9955213665962219),\n",
       " ('something', 0.9955205917358398),\n",
       " ('mmm', 0.9954789876937866),\n",
       " ('half', 0.9950986504554749),\n",
       " ('is', 0.9949543476104736)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"ayy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('everyday', 0.99904865026474),\n",
       " ('we', 0.9976405501365662),\n",
       " ('savage', 0.9975906610488892),\n",
       " (\"we're\", 0.9973452091217041),\n",
       " ('huh', 0.9971327781677246),\n",
       " ('too', 0.9970729351043701),\n",
       " ('always', 0.9969790577888489),\n",
       " ('word', 0.9969733953475952),\n",
       " ('even', 0.9969518184661865),\n",
       " ('pow', 0.9969456791877747)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"lit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('old', 0.9995255470275879),\n",
       " ('new', 0.9994903206825256),\n",
       " ('done', 0.9994865655899048),\n",
       " ('some', 0.9994511008262634),\n",
       " ('thing', 0.9994285106658936),\n",
       " ('around', 0.9994115233421326),\n",
       " ('â€™', 0.9994072914123535),\n",
       " ('every', 0.9994053840637207),\n",
       " ('fake', 0.9993884563446045),\n",
       " (\"'em\", 0.9993798732757568)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"ya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('something', 0.9985918402671814),\n",
       " ('atlanta', 0.9984863996505737),\n",
       " ('mmm', 0.9984734058380127),\n",
       " ('heart', 0.9982953071594238),\n",
       " ('east', 0.9982645511627197),\n",
       " ('huh', 0.9981123208999634),\n",
       " ('spy', 0.9980679750442505),\n",
       " ('little', 0.9979969263076782),\n",
       " ('woo', 0.9978418946266174),\n",
       " ('him', 0.9978407025337219)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"uh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"she's\", 0.999321460723877),\n",
       " ('took', 0.9991893768310547),\n",
       " ('had', 0.9991296529769897),\n",
       " ('thing', 0.9991273880004883),\n",
       " ('am', 0.9991133809089661),\n",
       " ('him', 0.9990891218185425),\n",
       " ('have', 0.9990624189376831),\n",
       " ('say', 0.999060332775116),\n",
       " ('four', 0.9990592002868652),\n",
       " ('much', 0.9990552663803101)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"woo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('havana', 0.9942862391471863),\n",
       " ('lovers', 0.9781044721603394),\n",
       " ('simple', 0.9767463803291321),\n",
       " ('ayy', 0.974694013595581),\n",
       " ('year', 0.9730695486068726),\n",
       " ('na', 0.9705337882041931),\n",
       " ('half', 0.969959557056427),\n",
       " ('east', 0.9672977924346924),\n",
       " ('hey', 0.9666562676429749),\n",
       " ('atlanta', 0.9657219648361206)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"ooh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main takeaways:\n",
    "\n",
    "- With 100 songs, we don't have much data to accurately estimate relationships between words.\n",
    "- Massively overfits to our dataset (the similarities are *much* too high to be realistic)\n",
    "- However, our VSM scores words highly if they appear near each other.\n",
    " - feeling\n",
    "   - more\n",
    "   - this\n",
    "   - real\n",
    "   - etc.\n",
    "   \n",
    "Next steps: definitely start scraping older Billboards. The pipeline is pretty good (ask Dr. Bodwin to check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
